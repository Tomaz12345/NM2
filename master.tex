\documentclass[a4paper,12pt]{article}

% General document formatting
%\usepackage[margin=0.7in]{geometry}
\usepackage[parfill]{parskip}
\usepackage{url, hyperref}
\usepackage{color}
\usepackage[usestackEOL]{stackengine}[2013-10-15] % formatting Pascal
\usepackage[dvipsnames]{xcolor}

\usepackage{cancel}
\usepackage[export]{adjustbox}

% Related to math
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{mathtools}
\usepackage{tikz}
\DeclarePairedDelimiter\norm{\lVert}{\rVert}
\newcommand{\innerproduct}[2]{\langle #1, #2 \rangle}
\usepackage{algorithm}
\usepackage{algpseudocode}

% encoding and language
\usepackage{lmodern}
\usepackage[slovene]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[mathscr]{euscript}

% multiline comments
\usepackage{verbatim}

% images
\usepackage{graphicx}
\graphicspath{ {./images/} }

% theorems
\theoremstyle{definition}
\newtheorem{counter}{Counter}[section] % not for use
\newtheorem{defn}[counter]{Definicija}
\newtheorem{lemma}[counter]{Lema}
\newtheorem{conseq}[counter]{Posledica}
\newtheorem{claim}[counter]{Trditev}
\newtheorem{theorem}[counter]{Izrek}
%%
\theoremstyle{remark}
\newtheorem*{ex}{Primer}
\newtheorem*{rem}{Opomba}
\newtheorem{rem*}[counter]{Opomba}
\newtheorem{ex*}[counter]{Primer}

% I like my squares DARK
\renewcommand\qedsymbol{$\blacksquare$}

% common commands redefined convenience purposes
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Pp}{\mathbb{P}}
\newcommand{\ch}{\operatorname{char}}


\begin{document}

%\title{Numeri"cne metode 2\\ \small zapiski s predavanj prof. Marjetke Knez}
%\author{Domen Vogrin}
%\date{pomlad 2023}
%\maketitle

\begin{titlepage}
    \begin{center}
        
        \vspace*{3cm}
            
        \Huge
        \textbf{Numerične metode 2}

        \large
        Zapiski s predavanj prof. Marjetke Knez

        \vspace*{0.5cm}
        \LARGE
        Domen Vogrin

        \vfill
        \normalsize
        Ljubljana, pomlad 2023
    \end{center}

\end{titlepage}

\clearpage

\pagenumbering{roman}
\tableofcontents
\newpage
\pagenumbering{arabic}


% 13. 2. 2023
\section{Teorija aproksimacije}

\subsection{Aproksimacija funkcij}
Denimo, da imamo podano funkcijo $f$. Radi bi jo aproksimirali s kak"sno 'preprostej"so' funkcijo $\tilde{f}$, ki bi bila la"zje izra"cunljiva, bi se jo dalo enostavno odvajati, integrirati \dots

\begin{ex}
    \[sin(x) \sim x - \frac{x^3}{3!} + \frac{x^5}{5!}\]
\end{ex}


Klju"cna vpra"sanja, ki se nam postavijo, so:
\begin{itemize}
    \item V kak"sni mno"zici/podprostoru naj i"s"cemo aproksimant $\tilde{f}$?
    \item V "cem naj si bo $\tilde{f}$ podobna/sorodna z $f$?
    \item Ali $\tilde{f}$ obstaja (v mno"zici, kjer jo i"s"cemo)?
    \item "ce obstaja, ali je dolo"cen enoli"cno?
    \item Kako konstruirati aproksimant $\tilde{f}$?
    \item Kako dobro nadomestilo za $f$ je izra"cunan $\tilde{f}$?
\end{itemize}

V splo"snem aproksimacijski problem formaliramo takole:

z $X$ ozna"cimo vektorski prostor, katerega elemente "zelimo aproksimirati, $S \subseteq X$ naj ozna"cuje podprostor/podmno"zico v $X$, v katerem i"s"cemo aproksimante. Aproksimacijska shema je operator 
\begin{equation*}
    \mathscr{A}\colon X \to S
\end{equation*}
ki vsakemu elementu $f \in X$ priredi aproksimacijski element (aproksimant)
\begin{equation*}
    \tilde{f} = \mathscr{A} f \in S
\end{equation*}

\begin{ex}
    Vektorski prostori:
    \begin{itemize}
        \item $X = \mathscr{C}([a, b]), X = \mathscr{C}^k([a, b])$
        \item $X = \ell^{2}_{\rho}([a, b]) = \{f\colon[a, b] \to \R$ $\int_{a}^{b} f^2(x)\rho(x) dx < \infty \}$,\\
        pri "cemer je $\rho \textbf{ pozitivna ute"z: } \rho (x) > 0$ za vsak $x \in [a, b]$
        \item $X = \R ^n$
    \end{itemize}
\end{ex}

\begin{ex}
    Podprostori, v katerih i"s"cemo aproksimante:
    
    \begin{itemize}
        \item $S = \Pp_n = Lin\{1, x, x^2, \dots, x^n\}$ polinomi stopnje $\leq$ $n$:
        \begin{equation*}
            S = \{ \sum_{i = 0}^{n} a_i x^i; a_i \in \R \}
        \end{equation*}
        \item $\textbf{triginimetri"cni polinomi}$
        \begin{equation*}
            S = Lin\{1, \sin x, \cos x, \sin 2x, \cos 2x, \dots, \sin nx, \cos nx\}
        \end{equation*}
        \item podprostori racionalnih funkcij, odsekoma polinomskih funkcij
    \end{itemize}
\end{ex}

Da bomo lahko definirali aproksimacijski problem in tudi ocenili napako aproksimacije, potrebujemo \textbf{normo}. Najbolj znane norme na prostoru funkcij so naslednje:

\begin{itemize}
    \item neskon"cna norma ($\norm{f}_{\infty}$)
    \begin{equation*}
        f \in \mathscr{C}([a, b]), \norm{f}_{\infty, [a, b]} = \max_{x \in [a, b]} \left| f(x) \right|
    \end{equation*}
    Za izra"cun numeri"cnega pribli"zka za neskon"cno normo na intervalu $[a, b]$ izberemo dovolj gosto zaporedje to"ck:
    \begin{equation*}
        a \leq x_0 < x_1 < \dots < x_n \leq b, \textbf{x} = (x_i)_{i=0}^N
    \end{equation*}
    in izra"cunamo
    \begin{equation*}
        \norm{f}_{\infty, \textbf{x}} = \max_{i = 0, \dots, N} \left| f(x_i) \right|
    \end{equation*}

    \item druga norma ($\norm{\cdot}_2$) - norma, porojena iz skalarnega produkta.
    Naj bo vektorski prostor $X$ opremljen s skalarnim produktom $\innerproduct{\cdot}{\cdot}$. Potem je 
    \begin{equation*}
        \norm{f}_2 = \sqrt{\innerproduct{f}{f}}, f \in X
    \end{equation*}
    Primeri skalarnih produktov:
    \begin{enumerate}
        \item[$\cdot$] $\innerproduct{f}{g} = \int_{a}^{b} f(x) g(x) \rho(x) dx$, $f, g \in \ell_{\rho}^2 ([a, b])$
        \item[$\cdot$] $\norm{f}_2 = \sqrt[]{\int_{a}^{b} f^2(x)\rho(x)dx }$
        
        Za $f(x) \equiv 1$ to imenujemo $\textbf{standardni skalarni produkt}$
    \end{enumerate}

    \item diskretni semi-skalarni produkt
    \begin{equation*}
        \textbf{x} = (x_i)_{i=0}^N \text{, }a \leq x_0 < x_1 < \dots < x_n \leq b
    \end{equation*}
    \begin{equation*}
        \innerproduct{f}{g} = \sum_{i = 0}^{N} f(x_i) g(x_i) \rho(x_i)
    \end{equation*}
    "Ce ga "se delimo z dol"zino intervala, dobimo pribli"zek za prej"snjega.
    \begin{equation*}
        \norm{f}_{2, \textbf{x}} = \sqrt[]{\sum_{i = 0}^{N} f^2(x_i)\rho(x_i)}
    \end{equation*}
\end{itemize}


Za dolo"canje aproksimanta $\tilde{f}$ lo"cimo dva primera:
\begin{enumerate}
    \item Optimalni aproksimacijski problemi
    \item interpolacija
\end{enumerate}


\subsubsection{Splo"sen optimalni aproksimacijski problem}
Naj bo $X$ vektorski prostor z normo $\norm{\cdot}$, $S \subseteq X$. Za $f \in X$ i"s"cemo $\tilde{f} \in S$, da velja
\begin{equation*}
    \norm{f - \tilde{f}} = \inf_{s \in S} \norm{f - s} = dist(f, S)
\end{equation*}
Torej, izmed mo"znih pribli"zkov izberemo najbolj"sega.


Pri tem predmetu si bomo ogledali:
\begin{enumerate}
    \item aproksimacijo po metodi najmanj"sih kvadratov
    
    (za normo izberemo drugo normo - normo iz skalarnega produkta)
    \item enakomerna polinomska aproksimacija ($X = C([a, b])$, $S = \Pp_n$, $\norm{\cdot}_{\infty}$)
\end{enumerate}

Polinomi so zelo uporabni pri aproksimaciji funkcij, saj so gosti v prostoru zveznih funkcij.

\begin{theorem} (Weierstrassov izrek)
    Naj bo $f \in \mathscr{C} ([a, b])$. Potem za vsak $\varepsilon > 0$ obstaja polinom $p$, da je $\norm{f - p}_{\infty, [a, b]} < \varepsilon$. Drugače povedano:
    \begin{equation*}
        dist(f, \Pp_n) \to 0 \text{, ko gre } n \to \infty
    \end{equation*}
\end{theorem}

\begin{proof}(konstruktivni - ideja)
    Naj bo $[a, b] = [0, 1]$. Za $f \in \mathscr{C} ([0, 1])$ definiramo t.i. $\textbf{Bernsteinov polinom}$:
    \begin{equation*}
        \mathscr{B}_n f (x) = \sum_{i = 0}^{n} f (\frac{i}{n}) B_i^n(x)
    \end{equation*}
    kjer je $B_i^n(x)$ $\textbf{Bernsteinov bazni polinom}$:
    \begin{equation*}
        B_i^n (x) = {n \choose i} x^i (1-x)^{n-i} \text{, } i = 0, 1, \dots, n  
    \end{equation*}
    Da se pokazati, da gre $\norm{f - \mathscr{B}_n f}_{\infty, [a, b]} \to 0$, ko gre $n \to \infty$.
\end{proof}

Bernsteinov aproksimacijski polinom nam poda en mo"zen na"cin aproksimacije funkcije $f$ (na $[0, 1]$).

Bernsteinov aproksimacijski operator:

\begin{equation*}
    \mathscr{B}_n : \mathscr{C} ([a, b]) \to \Pp_n
\end{equation*}
\begin{equation*}
    f \mapsto \mathscr{B}_n f
\end{equation*}
\begin{equation*}
    \mathscr{B}_n f(x) = \sum_{i = 0}^{n} f(a + \frac{i}{n}(b-a)) B_i^n (\frac{x-a}{b-a})
\end{equation*}

Po Weierstrassovem izreku imamo zagotovljeno konvergenco v neskon"cni normi, "zal pa je konvergenca zelo po"casna.



% 20. 2. 2023
\subsection{Aproksimacija po metodi najmanjših kvadratov (MNK)}
Sodi pod optimalne aproksimacijske probleme.

Naj bo $X$ normiran vektorski prostor nad $\R$ s skalarnim produktom $\innerproduct{\cdot}{\cdot}$ in naj bo $\norm{\cdot}_2 = \sqrt[]{\innerproduct{\cdot}{\cdot}}$.
$S \subseteq X$ naj bo končno dimenzionalen podprostor v $X$, $S = Lin\{\varphi_1, \varphi_2, \dots, \varphi_n\}$, $dimS = n$. Za izbran $f \in X$ iščemo $f^* \in S$, da bo veljalo
\begin{equation*}
    \norm{f - f^*}_2 = \min_{s\in S} \norm{f - s}_2
\end{equation*}

$f^*$ naj bo element najbližje aproksimacije (ENA) po MNK za $f \in X$.

\begin{theorem}
    Naj bo $S \subseteq X$ končno dimenzionalen podprostor. Element $f^* \in S$ je element najbližje aproksimacije po MNK za $f \in X$ natanko takrat,
    ko je
    \begin{equation*}
        f - f^* \perp S
    \end{equation*}
    oziroma
    \begin{equation*}
        \innerproduct{f - f^*}{S} = 0
    \end{equation*}
\end{theorem}

\begin{proof}
    $\\$
    ($\Longleftarrow$)
    Predpostavimo, da je $f - f^* \perp S$. Dokazati moramo, da je 
    \[\norm{f - f^*}_2 = \min_{s \in S} \norm{f-s}_2\]
    Izberimo poljuben $s \in S$.
    \begin{align}
        \norm{f - s}_2^2 &=  \norm{f - f^* + f^* - s}_2^2 \nonumber \\
                         &= \innerproduct{(f - f^*) + (f^* - s)}{(f - f^*) + (f^* - s)} \nonumber \\
                         &= \norm{f - f^*}_2^2 + 2 \cdot \innerproduct{f^* - s}{f - f^*} + \norm{f^* - s}_2^2 \nonumber \\
                         \label{eq:dokazNeenakost1}
                         &\geq \norm{f - f^*}_2^2 
    \end{align}
    Neenakost~\ref{eq:dokazNeenakost1} velja, saj zato, ker velja tako $f^* \in S$ kot $s \in S$ velja tudi $(f^* - s) \in S$,
    torej veljata tudi enakost $\innerproduct{f^* - s}{f - f^*} = 0$ in neenakost $\norm{f^* - s}_2 \geq 0$.

    ($\Longrightarrow$)
    Predpostavimo, da je $f^*$ ENA po MNK.
    Dokazati želimo
    \begin{equation*}
        f - f^* \perp S
    \end{equation*}

    $\forall s \in S$ in $\forall \lambda > 0$ velja
    \begin{align*}
        \norm{f - f^*}_2^2 &\leq \norm{f - (f^* - \lambda s)}_2^2 \\
                           &= \innerproduct{f - f^* + \lambda s}{f - f^* + \lambda s} \\
                           &= \norm{f-f^*}_2^2 + 2 \cdot \innerproduct{f - f^*}{\lambda s} + \lambda^2 \norm{s}_2^2
    \end{align*}

    \begin{align}
        0 &\leq 2 \innerproduct{f - f^*}{\lambda s} + \lambda^2 \norm{s}_2^2 \nonumber \\
        \label{eq:prviLambda}
        0 &\leq \lambda (2 \innerproduct{f-f^*}{s} + \lambda \norm{s}_2^2)\\
        \label{eq:drugiLambda}
        0 &\leq \innerproduct{f-f^*}{s} + \lambda \norm{s}_2^2
    \end{align}
    
    pri čemer iz ~\ref{eq:prviLambda} na ~\ref{eq:drugiLambda} pridemo preko začetnega izbora za $\lambda > 0$. Ker lahko $\lambda$ vzamemo tako majhno, da velikost člena $2\innerproduct{f-f^*}{s}$ prevlada nad $\lambda \norm{s}_2^2$, vidimo,
    da mora biti $0 \leq \innerproduct{f-f^*}{s}$. Če sedaj v $S$ izberemo element $-s$, potem po istem sklepu velja, da mora biti
    $0 \leq \innerproduct{f - f^*}{-s}$ oziroma $\innerproduct{f - f^*}{s} \leq 0$. Sledi, da mora biti
    \begin{equation*}
        \innerproduct{f - f^*}{s} = 0
    \end{equation*}
\end{proof}

Iz izreka sledi konstrukcija.

Izberemo $f \in X$. Naj bodo $\varphi_1, \varphi_2, \dots, \varphi_n$ baza za $S \subseteq X$:
\begin{equation*}
    S = Lin\{\varphi_1, \varphi_2, \dots, \varphi_n\}
\end{equation*}

Iščemo $f^* \in S$ ENA po MNK.
\begin{equation*}
    f^* = \sum_{j = 1}^{n} \alpha_j \varphi_j
\end{equation*}

kjer so $(\alpha_j)_{j = 1}^n$ neznani koeficienti. Iz izreka sledi, da mora biti $f - f^* \perp S$. To bo res, ko bo
\begin{equation*}
    f - f^* \perp \varphi_i, i \in [n]
\end{equation*}
\begin{align*}
    0 =& \innerproduct{f - f^*}{\varphi_i}\\
      =& \innerproduct{f - \sum_{j = 1}^{n}\alpha_j \varphi_j}{\varphi_j}\\
      =& \innerproduct{f}{\varphi_i} - \sum_{j = 1}^{n}\alpha_j \innerproduct{\varphi_j}{\varphi_i}
\end{align*}
Za vsak i tako dobimo enačbo
\begin{equation*}
    \sum_{j = 1}^{n} \alpha_j \innerproduct{\varphi_j}{\varphi_i} = \innerproduct{f}{\varphi_i}
\end{equation*}
iz česar skupaj dobimo sistem linearnih enačb. Če zgornje zapišemo po vektorjih, dobimo

\begin{equation*}
    \begin{bmatrix}
        \innerproduct{\varphi_1}{\varphi_i} & \innerproduct{\varphi_2}{\varphi_i} & \cdots & \innerproduct{\varphi_n}{\varphi_i}
    \end{bmatrix}
    \begin{bmatrix}
        \alpha_1 \\
        \alpha_2 \\
        \vdots \\
        \alpha_n
    \end{bmatrix}
    =
    \innerproduct{f}{\varphi_i} \text{, } i \in [n]
\end{equation*}

V matrični obliki:
\begin{equation*}
    \begin{bmatrix}
        \innerproduct{\varphi_1}{\varphi_1} & \innerproduct{\varphi_2}{\varphi_1} & \cdots & \innerproduct{\varphi_n}{\varphi_1} \\
        \innerproduct{\varphi_1}{\varphi_2} & \innerproduct{\varphi_2}{\varphi_2} & \cdots & \innerproduct{\varphi_n}{\varphi_2} \\
        \vdots & \vdots & & \vdots \\
        \innerproduct{\varphi_1}{\varphi_n} & \innerproduct{\varphi_2}{\varphi_n} & \cdots & \innerproduct{\varphi_n}{\varphi_n}
    \end{bmatrix}
    \begin{bmatrix}
        \alpha_1 \\
        \alpha_2 \\
        \vdots \\
        \alpha_n
    \end{bmatrix}
    =
    \begin{bmatrix}
        \innerproduct{f}{\varphi_1}\\
        \innerproduct{f}{\varphi_2}\\
        \vdots \\
        \innerproduct{f}{\varphi_n}
    \end{bmatrix}
\end{equation*}

\subsubsection{Normalni oziroma Gramov sistem enačb}
Gramova matrika G
\begin{equation*}
    G = (\innerproduct{\varphi_j}{\varphi_i})_{i, j = 1}^n
\end{equation*}
je $\textbf{simetrična}$ matrika. Gramova matrika je tudi pozitivno definitna. To dokažemo tako, da izberemo $x \in \R^n, x \neq 0$.
\begin{align}
    x^T G x =&
    \begin{bmatrix}
        x_1 & x_2 & \cdots x_n
    \end{bmatrix}
    \begin{bmatrix}
        \sum_{j = 1}^{n} x_j \innerproduct{\varphi_j}{\varphi_1} \\
        \vdots \\
        \sum_{j = 1}^{n} x_j \innerproduct{\varphi_j}{\varphi_n}
    \end{bmatrix} \nonumber \\
    =& \sum_{i = 1}^{n} x_i \sum_{j = 1}^{n} x_j \innerproduct{\varphi_j}{\varphi_1} \nonumber \\
    =& \sum_{i = 1}^{n} \sum_{j = 1}^{n} \innerproduct{x_j \varphi_j}{x_i \varphi_1} \nonumber \\
    =& \innerproduct{\sum_{j = 1}^{n} x_j \varphi_j}{\sum_{i = 1}^{n} x_i \varphi_1} \nonumber\\
    =& \norm{\sum_{i = 1}^{n} x_i \varphi_i}_2^2 \nonumber \\
    >& 0 \label{eq:grammNeenacaj}
\end{align}

Neenačaj~\ref{eq:grammNeenacaj} je strog, saj velja
\begin{equation*}
    \sum_{i = 1}^{n} x_i \varphi_i \neq 0
\end{equation*}
To je res zato, ker je $x_i > 0$ in ker je
\begin{equation*}
    \varphi_i \in Lin\{\varphi_1, \varphi_2, \dots, \varphi_n\}
\end{equation*}
kar je baza za $S$. Dobljeni sistem enačb lahko rešimo z razcepom Choleskega.

\begin{ex}
    Naj bo $f(x) = sin (x)$, $\innerproduct{f}{g} = \int_{0}^{\pi} f(x) g(x) dx$. Aproksimiraj $f$ po MNK v podprostoru $\Pp_1$.

    Rešitev:
    Definirajmo X in S
    \[X = \mathscr{C} ([0, \pi]) (X = \ell^2 ([0, \pi]))\]
    \[S = \Pp_1 = Lin\{1, x\}, \varphi_1(x) = 1, \varphi_2 (x) = x\]
    Zdaj definiramo $f^*$
    \[f^*(x) = \alpha_1 \varphi_1(x) + \alpha_2 \varphi_2(x)\]
    Imamo Gramovo matriko $G$
    \begin{equation*}
        \begin{bmatrix}
            \innerproduct{\varphi_1}{\varphi_1} & \innerproduct{\varphi_2}{\varphi_1}\\
            \innerproduct{\varphi_1}{\varphi_2} & \innerproduct{\varphi_2}{\varphi_2}
        \end{bmatrix}
        =
        \begin{bmatrix}
            \pi & \frac{\pi^2}{2} \\
            \frac{\pi^2}{2} & \frac{\pi^3}{3}
        \end{bmatrix}
    \end{equation*}
    \begin{equation*}
        \text{desna stran } =
        \begin{bmatrix}
            \innerproduct{f}{\varphi_1} \\
            \innerproduct{f}{\varphi_2}
        \end{bmatrix}
        =
        \begin{bmatrix}
            2 \\
            \pi
        \end{bmatrix}
    \end{equation*}
    Zgornji izračuni prihajajo iz postopkov
    \begin{align*}
        \innerproduct{\varphi_1}{\varphi_1} =& \int_{0}^{\pi} dx = \pi \\
        \innerproduct{\varphi_1}{\varphi_2} =& \int_{0}^{\pi} x dx = \frac{\pi^2}{2} \\
        \innerproduct{\varphi_2}{\varphi_2} =& \int_{0}^{\pi} x^2 dx = \frac{\pi^3}{3}
    \end{align*}
    in
    \begin{align*}
        \innerproduct{f}{\varphi_1} = \int_{0}^{\pi} sin x dx = - cos x \Biggr|_{0}^{\pi} = 2 \\
        \innerproduct{f}{\varphi_2} = \int_{0}^{\pi} x \cdot sin x dx = \dots = \pi
    \end{align*}
    Dobimo:
    \begin{equation*}
        \begin{bmatrix}
            \pi & \frac{\pi^2}{2} \\
            \frac{\pi^2}{2} & \frac{\pi^3}{3}
        \end{bmatrix}
        \begin{bmatrix}
            \alpha_1 \\
            \alpha_2
        \end{bmatrix}
        =
        \begin{bmatrix}
            2 \\
            \pi
        \end{bmatrix}
    \end{equation*}
    Ko poračunamo sistem enačb, dobimo
    \begin{equation*}
        \alpha =
        \begin{bmatrix}
            \frac{2}{\pi} \\
            0
        \end{bmatrix}
    \end{equation*}

    Geometrijska interpretacija rešitve:
    \begin{equation*}
        \min_{p \in \Pp_1} \norm{f - p}_2 = \min_{p \in \Pp_1} \sqrt[]{\int_{0}^{\pi} (sinx - p(x)^2) dx}
    \end{equation*}

    % izboljšaj, če ti uspe
    \begin{tikzpicture}
        \draw[->] (-1, 0) -- (3.5, 0);
        \draw[->] (0, -1) -- (0, 2);
        \draw[smooth, blue] (0, 0) sin (1.57, 1);
        \draw[smooth, blue] (1.57, 1) cos (3.14, 0);
        \draw[smooth, red] (0, 0.64) -- (3.14, 0.64);
    \end{tikzpicture}

    Želimo minimizirati ploščino območja med modro in rdečo črto.
\end{ex}

\begin{ex}
    Točke $(1, 2), (2, 3), (3, 5), (4, 8)$ aproksimiraj po MNK s premico.

    Rešitev:
    $S = \Pp_1 = Lin\{1, x\}$
    \begin{equation*}
        \innerproduct{f}{g} = \sum_{i = 1}^{4} f(x_i), g(x_i) \text{, } x =
        \begin{bmatrix}
            1 \\
            2 \\
            3 \\
            4
        \end{bmatrix}
    \end{equation*}
    $f$, ki jo aproksimiramo, je znana le v točkah $\textbf{x}$.

    Izračunamo:
    \begin{align*}
        \innerproduct{1}{1} =& \sum_{i = 1}^{4}1\cdot 1 = 4 \\
        \innerproduct{1}{x} =& \sum_{i = 1}^{4}1\cdot x_i = 10 \\
        \innerproduct{x}{x} =& \sum_{i = 1}^{4}x_i^2 = 30 \\
        \innerproduct{f}{1} =& \sum_{i = 1}^{4} y_i \cdot 1 = 18 \\
        \innerproduct{f}{x} =& \sum_{i = 1}^{4} y_i x_i = 55
    \end{align*}

    Dobimo sistem
    \begin{equation*}
        \begin{bmatrix}
            4 & 10 \\
            10 & 30
        \end{bmatrix}
        \begin{bmatrix}
            \alpha_1 \\
            \alpha_2
        \end{bmatrix}
        =
        \begin{bmatrix}
            18 \\
            55
        \end{bmatrix}
    \end{equation*}
    iz katerega dobimo rezultat
    \[ \alpha = 
        \begin{bmatrix}
            -\frac{1}{2} \\
            2
        \end{bmatrix}\]

    Geometrijska interpretacija rešitve:
    \begin{equation*}
        \min_{p \in \Pp_1} \norm{f - p}_2 =\sqrt[]{\sum_{i = 1}^{4} (y_i -p(x_i))^2}
    \end{equation*}
    % TODO: dodaj skico
\end{ex}

\subsubsection{Povezava s predoločenimi sistemi enačb}
\begin{equation*}
    Ax = b \text{, } A\in \R^{m \times n} \text{, } A = 
    \begin{bmatrix}
        a_1 & a_2 & \dots & a_n
    \end{bmatrix} \text{, }  b \in R^m
\end{equation*}
\begin{equation*}
    \min_{x \in \R^n} \norm{Ax - b}_2 = \min_{z \in ImA} \norm{b - z}
\end{equation*}

Aproksimiramo vektor $b \in \R^m (X = \R^m)$
\begin{equation*}
    S = Lin\{a_1, a_2, \dots, a_n\} = ImA
\end{equation*}
\begin{equation*}
    b^* = \sum_{j = 1}^{n}x_j a_j = Ax
\end{equation*}
\begin{equation*}
    \innerproduct{x}{y} = \sum_{i = 1}^{m}x_i y_i = x^T y
\end{equation*}

$\innerproduct{x}{y} = \sum_{i = 1}^{m} x_i y_i$:
\begin{equation}
    G = (\innerproduct{a_j}{a_i})_{i, j = 1}^n = A^T A
\end{equation}
\begin{equation}
    \text{desna stran } = (\innerproduct{a_i}{b})_{i = 1}^n = A^Tb
\end{equation}

\begin{ex}
    $X = \mathscr{C} ([0, 1])$
    \begin{equation*}
        S = P_{n-1} = Lin\{1, x, x^2, \dots, x^{n-1}\}
    \end{equation*}
    \begin{equation*}
        \innerproduct{f}{g} = \int_{0}^{1} f(x) g(x) dx
    \end{equation*}
    \begin{equation*}
        \innerproduct{\varphi_i}{\varphi_j} = \int_{0}^{1} x^{i-1} x^{j-1} dx = \int_{0}^{1}x^{i+j-2} dx = \frac{1}{i+j-1}
    \end{equation*}
    \begin{equation*}
        G = (\frac{1}{i+j-1})_{i, j = 1}^n
    \end{equation*}
    kjer je G Hilbertova matrika. Te so zelo občutljive.
\end{ex}

% 24. 2. 2023

Gramova matrika je lahko zelo občutljiva. Reševanju sistema linearnih enačb se izognemo, če v podprostoru $S$ izberemo $\textbf{ortonormirano bazo}$:
\begin{equation*}
    \{\varphi_1, \varphi_2, \dots, \varphi_n\}
\end{equation*}
je ortonormirana baza, če
\begin{equation*}
    \varphi_1 \perp \varphi_j \text{ } \forall i \neq j \text{ in } \norm{\varphi_i}_2 = 1
\end{equation*}
V tem primeru je $G = I$ in $\alpha_i = \innerproduct{f}{\varphi_i}$,  $f^* = \sum_{i = 1}^{n}\innerproduct{f}{\varphi_i} \varphi_i$. Ortonormirano
bazo izračunamo z $\textbf{modificiranim Gram-Scmidtovim algoritmom}$.

\begin{algorithm}
    \caption{Modificiran Gram-Schmidtov algoritem}\label{alg:mgs}
    \hspace*{\algorithmicindent} \textbf{Input} baza $\{\psi_1, \psi_2, \dots, \psi_n\}$
    \begin{algorithmic}[1]
        \For{$i = 1:n$}
            \State $\varphi_i = \psi_i$
        \EndFor
        \For{$i = 1:n$}
            \State $\varphi_i = \frac{\varphi_i}{\norm{\varphi_i}_2}$
            \For{$j = i+1:n$}
                \State $\varphi_j = \varphi_j - \innerproduct{\varphi_j}{\varphi_i}\varphi_i$
            \EndFor
        \EndFor
    \end{algorithmic}
    \hspace*{\algorithmicindent} \textbf{Output} ortonormirana baza $\{\varphi_1, \varphi_2, \dots, \varphi_n\}$
\end{algorithm}


$X \in \mathscr{C}([a, b])$
(vstavi skico)

\subsection{Enakomerna aproksimacija zveznih funkcij s polinomi}
\begin{equation*}
    X = \mathscr{C} ([a, b]), S = \Pp_n, \norm{\cdot}_{\infty}
\end{equation*}

Problem: Za dano funkcijo $f \in \mathscr{C} ([a, b])$ iščemo polinom $p^* \in \Pp_n$, za katerega velja
\begin{equation*}
    \norm{f - p^*}_{\infty, [a, b]} = \min_{p \in \Pp_n} \norm{f - p}_{\infty, [a, b]} = \min_{p \in Pp_n} \max_{x \in [a, b]} \left| f(x) - p(x) \right|
\end{equation*}
$p^*$ imenujemo $\textbf{polinom najboljše enakomerne aproksimacije (PNEA)}$.
Problem je nelinearen.

(vstavi skico)

Nasledni izrek nam poda $\textbf{zadostni pogoj}$, da je nek polinom PNEA za neko funkcijo.
\begin{theorem}
    Naj bo $f \in \mathscr{C}([a, b])$. Če je polinom $p \in \Pp_n$ tak, da $\textbf{residual}$
    \begin{equation}
        r = f - p
    \end{equation}
    alternirajoče doseže svojo normo $\norm{p}_{\infty, [a, b]}$ v vsaj $n + 2$ različnih točkah $(x_i)_{i=0}^{n+1}$
    \[a \leq x_0 < x_1 < \dots < x_{n+1} \leq b\]
    Potem je $p$ polinom najboljše enakomerne aproksimacije za $f$ na $[a, b]$.
\end{theorem}

\rem{Kaj pomeni "alternirajoče doseže svojo normo"?}
\begin{equation*}
    \norm{r}_{\infty, [a, b]} = \left| r(x_i) \right| \forall i \in [n]
\end{equation*}
in
\begin{equation*}
    r(x_i)r(x_{i+1}) < 0 \forall i
\end{equation*}

(vstavi graf)

\begin{proof}
    Dokaz s protislovjem.

    Recimo, da $p$ ne bi bil PNEA za $f$. Tedaj bi obstajal nek drug polinom $q \in \Pp_n$, da bi veljalo
    \begin{align*}
        \left| f(x_i) - q(x_i) \right| \leq& \max_{x \in [a, b]} \left| f(x) - q(x) \right| \\
                             =& \norm{f - q}_{\infty, [a, b]} \\
                             <& \norm{f - p}_{\infty, [a, b]} \\
                             =& \left| f(x_i) - p(x_i) \right| \text{  } \forall i = 0, 1, 2, \dots, n+1
    \end{align*}
    Torej za $\forall i $ velja:
    \begin{equation*}
        \left| f(x_i) - q(x_i) \right| < \left| f(x_i) - p(x_i) \right|
    \end{equation*}
    To razvijemo v neenakosti
    \begin{equation*}
        - sign(f(x_i) - p(x_i)) (f(x_i) - p(x_i)) < f(x_i) - q(x_i)
    \end{equation*}
    in
    \begin{equation*}
        f(x_i) - q(x_i) < sign(f(x_i) - p(x_i)) (f(x_i) - p(x_i))
    \end{equation*}
    Če v neenakostih $x_i$ spremenimo v $x_{i+1}$ ter upoštevamo enakost
    \begin{equation*}
        sign(f(x_{i+1}) - p(x_{i+1})) = - sign(f(x_i) - p(x_i))
    \end{equation*}
    dobimo neenakosti
    \begin{equation*}
        sign(f(x_i) - p(x_i)) (f(x_{i+1}) - p(x_{i+1})) < f(x_{i+1}) - q(x_{i+1})
    \end{equation*}
    in
    \begin{equation*}
        f(x_{i+1}) - q(x_{i+1}) < - sign(f(x_i) - p(x_i)) (f(x_{i+1}) - p(x_{i+1}))
    \end{equation*}

    Brez škode za splošnost (BŠS) lahko rečemo, da je $sign(f(x_i) - p(x_i)) = 1$. Potem je $f(x_i) - q(x_i) < f(x_i) - p(x_i)$, $p(x_i) - q(x_i) < 0$ in
    $f(x_{i+1}) - p(x_{i+1}) < f(x_{i+1}) - q(x_{i+1})$, torej $p(x_{i+1}) - q(x_{i+1}) > 0$.

    Vidimo, da ima razlika $p-q$ ničlo na intervalu $(x_i, x_{i+1})$ za $i \in [n]$. Razlika $p-q$ je polinom stopnje $n$, ki ima $n+1$ ničel.
    Torej mora biti $p \equiv q$.
\end{proof}

Izkaže se, da je pogoj tudi potreben (torej da velja ekvivalenca), a je dokaz težek, zato ga bomo izpustili.

Iskanje/računanje PNEA se prevede na iskanje ustrezne množice točk $\{x_i, a \leq x_0 < x_1 < \dots < x_{n+1} \leq b\}$.

\begin{defn}
    Naj bo $E = \{x_i, a \leq x_0 < x_1 < \dots < x_{n+1} \leq b\}$. Definirajmo $\textbf{minimaks}$ za $f$ na $E$ konstruirati
    \begin{equation*}
        M_n (f, E) = \min_{p \in \Pp_n} \max_{x_i \in E} \left| f(x_i) - p(x_i) \right|
    \end{equation*}
\end{defn}

Polinom, pri katerem je ta minimum dosežen, imenujemo $\textbf{polinom}$ $\textbf{najboljše}$ $\textbf{enakomerne}$ $\textbf{aproksimacije}$ $\textbf{za}$ $f$
$\textbf{na}$ $\textbf{množici}$ $E$. Izračunamo ga tako,
da rešimo naslednji sistem linearnih enačb: (brez izpeljave)
\begin{equation*}
    f(x_i) - p(x_i) = (-1)^i m, i \in [n+1] 
\end{equation*}

Imamo torej $n+2$ enačb in $n+2$ neznank ($n + 1$ v polinomu $p$ in eno v $m$):
\begin{equation*}
    p(x) = \sum_{j = 0}^{n} a_j x^j
\end{equation*}
ter koeficient $m$, za katerega velja
\begin{equation*}
    \left| m \right| = M_n (f, E)
\end{equation*}

(vstavi slikco)

\section{Interpolacija}
Problem: Podane imamo vrednosti izbrane funkcije $f$ v $n+1$ paroma različnih točkah $x_0, x_1, \dots, x_n$ na realni osi. Te točke bomo imenovali
$\textbf{interpolacijske}$ $\textbf{točke}$. Iščemo neko preprostejšo funkcijo $g$, ki zadošča pohojem
\begin{equation*}
    g(x_i) = f(x_i) \forall i \in [n]
\end{equation*}
$g$ imenujemo $\textbf{interpolacijska}$ $\textbf{funkcija}$. Za interpolacijske funkcije običajno izberemo polinome, odsekoma polinomske funkcije \dots


% 27.2.2023
Interpolacija se uporablja za
\begin{itemize}
    \item aproksimacijo dane funkcije
    \item kadar funkcijo $f$ poznamo le v točkah $x_0, x_1, \dots, x_n$, radi pa bi izračunali vrednost te funkcije tudi za $x$, ki ni ena izmed interpolacijskih točk.
    \item za izpeljavo formul za numerično integriranje, odvajanje, reševanje navadnih diferencialnih enačb (NDE) \dots
\end{itemize}

\subsection{Polinomska interpolacija}
Za $f \in \mathscr{C}([a, b])$ in interpolacijske točke $a \leq x_0 < x_1 < \dots < x_m \leq b$ iščemo $\textbf{polinom}$ $p_i$, ki zadošča enačbam
\begin{equation*}
    p(x_i) = f(x_i), i = a, \dots, n
\end{equation*}
Enačb je $n+1$. Da dobimo enako število enačb, moramo izbrati $p \in \Pp_n$.

\begin{equation*}
    p(x) = a_0 + a_1 x + a_2 x^2 + \dots + a_n x^n
\end{equation*}

Enačbe (za $i = 0, 1, \dots, n$)
\begin{equation*}
    a_0 + a_1 x_i + a_2 x_i^2 + \dots + a_n x_i^n
\end{equation*}
lahko zapišemo matrično
\begin{equation*}
    \begin{bmatrix}
        1 & x_0 & x_0^2 & \dots & x_0^n \\
        1 & x_1 & x_1^2 & \dots & x_1^n \\
    \vdots & \vdots & \vdots &  & \vdots \\
        1 & x_n & x_n^2 & \dots & x_n^n 
    \end{bmatrix}
    \begin{bmatrix}
        a_0 \\
        a_1 \\
        \vdots \\
        a_n
    \end{bmatrix}
    =
    \begin{bmatrix}
        f(x_0) \\
        f(x_1) \\
        \vdots \\
        f(x_n) \\
    \end{bmatrix}
\end{equation*}
Matriko, ki jo uporabimo, imenujemo $\textbf{vandermondova matrika}$.
\begin{equation*}
    detV(x_0, x_1, \dots, x_n) = \prod_{0 \leq i < j \leq n} (x_j - x_i)
\end{equation*}

Ker je Vandermondova matrika obrnljiva, sledi, da imamo enolično rešitev. Torej obstaja $\textbf{enoličen}$ polinom stopnje $n$, ki interpolira $n+1$ paroma
različnih točk.
Tak interpolacijski problem imenujemo $\textbf{korenten}$ interpolacijski problem.
Vandermondova matrika je primer $\textbf{zelo občutljive}$ matrike.
Poleg tega nimamo rešitve v $\textbf{zaključeni obliki}$.
Spoznali bomo dva druga zapisa interpolacijskega polinoma:
\begin{itemize}
    \item Lagrangeva oblika zapisa
    \item Newtonova oblika zapisa
\end{itemize}

\subsubsection{Lagrangeva oblika zapisa interpolacijskega polinoma}
Definiramo naslednje polinome:
\begin{align*}
    \ell_{0, n} (x) =& \frac{(x-x_1)(x-x_2) \dots (x - x_n)}{(x_0 - x_1)(x_0 - x_2) \dots (x_0 - x_n)} \\
    \ell_{1, n} (x) =& \frac{(x-x_1)(x-x_2) \dots (x - x_n)}{(x_1 - x_0)(x_1 - x_2) \dots (x_1 - x_n)} \\
    \vdots &\\
    \ell_{n, n} (x) =& \frac{(x-x_1)(x-x_2) \dots (x - x_n)}{(x_n - x_0)(x_n - x_1) \dots (x_n - x_{n-1})}
\end{align*}

oziroma
\begin{equation*}
    \ell_{i, n} (x) = \prod_{j = 0, j \neq i}^{n} \frac{(x - x_j)}{(x_i - x_j)}
\end{equation*}
za $i = 0, 1, \dots, n$. To imenujemo $\textbf{Lagrangevi bazni polinomi}$.

Velja:
\begin{equation*}
    \ell_{i, n} (x) = \delta_{i, j} = \begin{cases}
        1 &; i = j \\
        0 &; i \neq j
    \end{cases}
\end{equation*}
Vsi ti polinomi so stopnje točno $n$.

\begin{theorem}
    Polinomi $\ell_{i, n}$ za $i = 0, 1, \dots, n$ so baza za $\Pp_n$.
\end{theorem}

\begin{proof}
    Dokazati moramo le, da so linearno neodvisni. Preveriti moramo, da je $\alpha_0 \ell_{i, n} +  \alpha_1 \ell_{i, n} + \dots +
    \alpha_n \ell_{i, n} = 0 <=> \alpha_0 = \alpha_1 = \dots = \alpha_n = 0$.

    ($\Longrightarrow$)
    \begin{equation*}
        \sum_{j = 0}^{n} \alpha_j \ell_{j, n} (x) = 0 \text{ }\forall x
    \end{equation*}
    Vstavimo $x = x_i$ in dobimo
    \begin{equation*}
        0 = \sum_{j = 0}^{n} \alpha_j \ell_{j, n} (x_i) = \sum_{j = 0}^{n} \alpha_j \delta_{i, j} = \alpha_i
    \end{equation*}
    ($\Longleftarrow$) Očitno.
\end{proof}

Iz dokaza izreka sledi, da lahko vsak polinom $p \in \Pp_n$ zapišemo kot linearno kombinacijo
\begin{equation*}
    p(x) = \sum_{j = 0}^{n} c_j \ell_{j, n} (x)
\end{equation*}
za $c_j \in \R$.

Kako izbrati koeficiente, da bo polinom interpolacijski oziroma da bo zadoščal pogojem
\begin{equation*}
    p(x_i) = \sum_{j = 0}^{n} c_j \ell_{j, n} (x_i) = f(x_i)
\end{equation*}
za $i = 1, \dots, n$. Za vsak $i$ je tudi vsota enaka $c_i$.

Dobili smo
\begin{equation*}
    p(x) = \sum_{j = 0}^{n} f(x_j) \ell_{j, n}(x)
\end{equation*}
kar je Lagrangeva oblika zapisa interpolacijskega polinoma.

\begin{ex}
    Naj bo $f(x) = e^x$. Pošiči interpolacijski polinom za $f$ na točkah $x_0 = 0, x_1 = 1, x_2 = 3, x_3 = 4$.
    Za $n = 3$ izračunamo

    \begin{align*}
        \ell_{0, 3}(x) =& \frac{(x-1)(x-3)(x-4)}{((0-1)(0-3)(0-4))} \\
                       =& -\frac{1}{12}(x-1)(x-3)(x-4) \\
        \ell_{1, 3}(x) =& \frac{x(x-3)(x-4)}{(1(1-3)(1-4))} \\
                       =& \frac{1}{6} x(x-3)(x-4) \\
        \ell_{2, 3}(x) =& \frac{x(x-1)(x-4)}{(3(3-1)(3-4))} \\
                       =& -\frac{1}{6} x(x-1)(x-4) \\
        \ell_{3, 3}(x) =& \frac{x(x-1)(x-3)}{(4(4-1)(4-3))} \\
                       =& \frac{1}{12} x(x-1)(x-3) \\
    \end{align*}

    in dobimo rešitev
    \begin{equation*}
        p(x) = e^0 \ell_{0, 3}(x) + e^1 \ell_{1, 3}(x) + e^3 \ell_{2, 3} (x) + e^4 \ell_{3, 3}(x)
    \end{equation*}
    Časovna zahtevnost za evaluacijo $\ell_{i, n}(x)$ v $x_i$ je $\mathcal{O}(n^2)$. Ker v praksi izpustimo skupen polinom,
    je končna časovna zahtevnost $\mathcal{O}(n)$, tako kot Hornerjev algoritem.
\end{ex}


\begin{lemma}
    Če je $f \in \Pp_n$, potem je $\sum_{i = 0}^{n} f(x_i) \ell_{i, n} (x) = f(x)$.
\end{lemma}
\begin{proof}
    Sledi iz enoličnosti interpolacijskega polinoma.
\end{proof}

\begin{conseq}
    \begin{equation}
        \sum_{i = 0}^{n} \ell_{i, n}(x) = 1
    \end{equation}
    Lagrangevi bazni polinomi tvorijo $\textbf{razčlenitev}$ oziroma $\textbf{razčlenitev enote}$, ki pozitivno vpliva na stabilnost baze.
\end{conseq}

\begin{theorem}[O napaki interpolacije.]
    Naj bodo $a \leq x_0 < x_1 \dots < x_n \leq b$, $f \in \mathscr{C}^{n+1}([a, b])$ in naj bo $p$ interpolacijski polinom za $f$ na teh točkah. Potem za vsak $x \in [a, b]$
    obstaja $\xi_x \in (a, b)$, da velja
    \begin{equation*}
        f(x) - p(x) = \omega (x) \frac{f^{(n+1)}(\xi_x)}{(n+1)!}
    \end{equation*}
    kjer velja
    \begin{equation*}
        \omega (x) = (x - x_0)(x-x_1) \dots (x - x_n)
    \end{equation*}
\end{theorem}

\begin{proof}
    Če je $x = x_i$, potem $f(x_i) - p(x_i) = 0$ in $\omega (x_i) = 0$ ter enakost velja za vsak $\xi_x \in (a, b)$. Naj bo sedaj $x \neq x_i$, $i = 0, 1, \dots, n$
    in naj bo ta $x$ fiksen.
    Definirajmo $F(u) = f(u) - p(u) - c \omega (u)$ za neko konstanto $c$, pri čemer za $F$ velja $F \in \mathscr{C}^{n+1}([a, b])$, $F(x_i) = f(x_i) - p(x_i) - c \omega (x_i) = 0$ za $i = 0, 1, \dots, n$.
    Konstanto $c$ izberemo tako, da bo tudi $F(x) = 0$. Torej ima $F$ na $[a, b]$ $n+2$ različnih ničel. Potem ima $F'$ na $(a, b)$ $n+1$ različnih ničel.
    Potem ima $F''$ na (a, b) n različnih ničel \dots Potem ima $F^{(n+1)}$ na $(a, b)$ vsaj eno ničlo. Označimo to ničlo z $\xi_x$. Torej je
    \begin{align*}
        0 =& F^{(n+1)}(\xi_x) \\
          =& f^{(n+1)}(\xi_x) - p^{(n+1)}(\xi_x) - c \omega ^{(n+1)}(\xi_x)
    \end{align*}
    Uporabimo razmislek od zgoraj in dobimo
    \begin{equation*}
        0 = f^{(n+1)}(\xi_x) - c (n+1)!
    \end{equation*}
    Ko to preuredimo, dobimo
    \begin{equation*}
        c = \frac{1}{(n+1)!}f^{(n+1)}(\xi_x)
    \end{equation*}
\end{proof}

Za poljuben $c \in [a, b]$ po izreku velja
\begin{equation*}
    \left| f(x) - p(x) \right| = \left| \omega \right| \frac{1}{(n+1)!} \left| f^{(n+1)}(\xi_x) \right| \leq \norm{\omega}_{\infty, [a, b]} \frac{1}{(n+1)!} \norm{f^{(n+1)}}_{\infty, [a, b]}
\end{equation*}
Iz tega sledi
\begin{equation*}
    \norm{f - p}_{\infty, [a, b]} \leq \frac{1}{(n+1)!} \norm{\omega}_{\infty, [a, b]} \norm{f^{(n+1)}}_{\infty, [a, b]}
\end{equation*}
Ta ocena je uporabna v teoriji, ne pa tudi v praksi.

Lagrangeva oblika je zaradi enostavnosti zelo uporabna pri izpeljavi formul za numerično integracijo, odvajanje \dots, ima pa tudi nekaj pomankljivosti pri praktični uporabi:
\begin{itemize}
    \item numerično računanje vrednosti polinoma v Lagrangevi obliki \dots
    \item Numerične težave, če so interpolacijske točke preblizu skupaj
    \item Konstrukcija ni rekurzivna. Dodajanje novih točk je zahtevno.
\end{itemize}

\subsubsection{Newtonova oblika zapisa interpolacijskega polinoma}
Za bazo, v kateri bomo predstavili interpolacijski polinom, izberemo $\\ \textbf{prestavljene}$ $\textbf{potence}$. % previdno z \\
\begin{equation*}
    \text{baza} = \{1, x-x_0, (x-x_0)(x-x_1), \dots, (x-x_0) (x-x_1) \dots (x-x_n)\}
\end{equation*}
% en odstavek manjka, ne znam prebrat :(

% 6. 3. 2023

\end{document}
